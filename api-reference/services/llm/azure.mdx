---
title: 'Azure'
description: 'Large Language Model service implementation using Azure OpenAI API'
---

## Overview

`AzureLLMService` extends the BaseOpenAILLMService to provide Azure-specific OpenAI model integration. It maintains compatibility with OpenAI's interface while using Azure's endpoints.

## Installation

To use `AzureLLMService`, install the required dependencies:

```bash
pip install pipecat-ai[azure]
```

You'll also need to set up the following environment variables:

- `AZURE_API_KEY`
- `AZURE_REGION`

## Configuration

### Constructor Parameters

<ParamField path="api_key" type="str" required>
  Azure OpenAI API key
</ParamField>

<ParamField path="endpoint" type="str" required>
  Azure OpenAI endpoint URL
</ParamField>

<ParamField path="model" type="str" required>
  Model deployment name
</ParamField>

<ParamField path="api_version" type="str" default="2023-12-01-preview">
  Azure OpenAI API version
</ParamField>

## Usage Example

```python
# Configure service
llm_service = AzureLLMService(
    api_key="your-api-key",
    endpoint="https://your-resource.openai.azure.com/",
    model="gpt-4",
    api_version="2023-12-01-preview"
)

# Use in pipeline
pipeline = Pipeline([
    context_manager,
    llm_service,
    response_handler
])
```
