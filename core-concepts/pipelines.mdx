---
title: Pipelines
description: 'Understanding pipelines - how to connect and orchestrate frame processors in Pipecat.'
---

## Pipeline Architecture

A pipeline is like an assembly line for your AI application. It connects frame processors together, creating a path for data to flow through your system. Each processor in the pipeline can transform data, generate new frames, or pass frames through unchanged.

Here's a simple pipeline with three processors, `p`, `q`, and `r`:

<Frame>
  ![Basic pipeline with three processors](/images/simple-pipeline.svg)
</Frame>

## Frame Ordering

To maintain predictable behavior, frames must maintain their order as they travel through the pipeline. The only exception is system frames, which can be sent out-of-band. This ordering is achieved through the **single push task rule** - each processor should only output frames from a single task.

## Pipeline Types

### Linear Pipelines

The simplest type of pipeline - processors connected in sequence:

```python
# Voice assistant pipeline
pipeline = Pipeline([
    transport.input(),      # Receive audio
    transcriber,           # Convert speech to text
    llm_processor,         # Generate response
    tts_service,          # Convert text to speech
    transport.output()     # Play audio
])
```

### Parallel Pipelines (Asynchronous)

Run multiple processing paths concurrently:

<Frame>
  ![Asynchronous parallel pipeline](/images/async-parallel-pipeline.svg)
</Frame>

```python
# AI avatar pipeline
pipeline = Pipeline([
    transport.input(),
    ParallelPipeline([
        [video_processor, avatar_generator],     # Handle video
        [audio_processor, speech_synthesizer]    # Handle audio
    ]),
    transport.output()
])
```

The single push task rule still applies - outputs from all parallel paths are combined and sent from a single task.

### Synchronous Parallel Pipelines

Similar to parallel pipelines, but waits for all paths to complete:

<Frame>
  ![Synchronous parallel pipeline](/images/sync-parallel-pipeline.svg)
</Frame>

```python
# Multimodal storyteller pipeline
pipeline = Pipeline([
    llm,                    # Generate story
    sentence_aggregator,    # Split into sentences
    SyncParallelPipeline([
        [tts],             # Generate narration
        [image_generator]  # Generate illustrations
    ]),
    transport.output()
])
```

## Frame Synchronization

There are three main approaches to synchronizing different types of frames:

### 1. Using Frame Processors

Best for simple synchronization with pre-loaded content:

```python
class TalkingAnimation(FrameProcessor):
    """Synchronizes avatar animations with speech"""
    async def process_frame(self, frame: Frame, direction: FrameDirection):
        if isinstance(frame, AudioRawFrame):
            if not self._is_talking:
                await self.push_frame(talking_frame)
                self._is_talking = True
        elif isinstance(frame, TTSStoppedFrame):
            await self.push_frame(quiet_frame)
            self._is_talking = False
```

When to use: When you have pre-loaded frames and need simple state-based synchronization.

### 2. Using Synchronous Parallel Pipelines

Ideal for generating synchronized content:

```python
# Story generator with synchronized audio and images
pipeline = Pipeline([
    llm,                  # Generate story text
    SyncParallelPipeline([
        [tts],           # Convert text to speech
        [image_gen]      # Generate matching image
    ]),
    transport.output()
])
```

When to use: When generating content that needs to stay synchronized, like matching audio and visuals for each part of a story.

### 3. Using Pipeline Clocks

Best for real-time audio/video synchronization:

```python
# Real-time AI avatar
pipeline = Pipeline([
    video_source.with_clock(pipeline_clock),
    audio_source.with_clock(pipeline_clock),
    output_sink
])
```

When to use: For applications requiring precise timing synchronization, like AI avatars or real-time video processing.

## Pipeline States

Pipelines can be in different states:

- `NULL` - Initial state
- `PLAYING` - Processing frames

```python
# Pipeline lifecycle
pipeline = Pipeline([...])

# Start processing
await pipeline.set_state(Pipeline.State.PLAYING)

# Stop pipeline
await pipeline.set_state(Pipeline.State.NULL)
```

## Best Practices

### Resource Management

```python
# Ensure proper cleanup
try:
    await pipeline.run()
finally:
    await pipeline.cleanup()
```

### Error Handling

```python
# Handle pipeline errors
@pipeline.error_handler
async def handle_error(error: Exception):
    logger.error(f"Pipeline error: {error}")
    await pipeline.set_state(Pipeline.State.NULL)
```

### Pipeline Design

1. **Single Responsibility**

```python
# Good - focused pipeline
transcription_pipeline = Pipeline([
    audio_input,
    vad_processor,
    transcriber,
    text_output
])

# Bad - mixing concerns
mixed_pipeline = Pipeline([
    audio_input,
    transcriber,
    image_processor,  # Unrelated processing
    text_output
])
```

2. **Parallel Processing**

```python
# Use parallel pipelines for independent processes
pipeline = Pipeline([
    input_source,
    ParallelPipeline([
        [audio_pipeline],
        [video_pipeline]
    ]),
    output_sink
])
```

3. **Frame Synchronization**

```python
# Consider synchronization needs early
pipeline = Pipeline([
    input_source,
    SyncParallelPipeline([
        [audio_generator],
        [animation_generator]
    ]),
    synchronizer,
    output_sink
])
```

## Common Patterns

### Voice Assistant

```python
pipeline = Pipeline([
    transport.input(),
    transcriber,
    context_aggregator,
    llm_service,
    tts_service,
    transport.output()
])
```

### AI Avatar

```python
pipeline = Pipeline([
    transport.input(),
    ParallelPipeline([
        [audio_processor, speech_generator],
        [video_processor, avatar_generator]
    ]),
    frame_synchronizer,
    transport.output()
])
```

### Interactive Storyteller

```python
pipeline = Pipeline([
    story_generator,
    SyncParallelPipeline([
        [narrator],
        [illustrator]
    ]),
    transport.output()
])
```

## Next Steps

Now that you understand pipelines, you can:

- Review [Frames](/core-concepts/frames) and [Processors](/core-concepts/processors)
- Explore example applications in our [GitHub repository](https://github.com/pipecat-ai/pipecat/tree/main/examples)
- Join our [Discord community](https://discord.gg/pipecat) for help and discussions
