---
title: Introduction
description: 'Pipecat is an Open Source framework for voice and multimodal conversational AI.'
---

<Note>
  Pipecat's documentation is currently work in progress. Whilst we aim to have
  this done soon, we have a lot to write! Please refer to the project source
  code in the meantime.
</Note>

## What is Pipecat?

Pipecat is a Python framework for building voice-enabled, real-time, multimodal AI applications. At its core, it's designed to handle the complex orchestration of streaming data between different AI services while maintaining real-time performance - making it particularly well-suited for building conversational AI agents.

```python
# A simple Pipecat pipeline example
pipeline = Pipeline([
    audio_source,      # Captures audio input
    transcriber,       # Converts speech to text
    llm_processor,     # Processes text with an LLM
    tts_service,       # Converts response to speech
    audio_output       # Plays audio response
])
```

Unlike traditional request-response frameworks, Pipecat is built around continuous data streams and real-time processing, making it ideal for:

- Voice-based AI assistants
- Interactive AI agents
- Multimodal chatbots
- Real-time AI processing systems
- Streaming media applications

Join our [Discord community](https://discord.gg/pipecat) to connect with other developers, share your projects, and get help when you need it.

## Key Features

### Real-time Processing

- Frame-based pipeline architecture for processing real-time data
- Support for both synchronous and asynchronous processing
- Built-in frame synchronization for multimodal applications

### Flexible Pipeline Architecture

```python
# Parallel processing example
pipeline = Pipeline([
    input_source,
    ParallelPipeline([
        [image_processor, image_generator],  # Image pipeline
        [audio_processor, tts_service]       # Audio pipeline
    ]),
    output_sink
])
```

### Service Integration

- Native support for popular AI services (OpenAI, ElevenLabs, etc.)
- WebRTC integration through Daily.co
- Extensible service architecture for custom integrations

### Developer-First Design

- Pure Python implementation
- Async/await support
- Clear separation of concerns between data, processing, and transport

## Use Cases

### Voice Assistants

Pipecat makes it easy to build voice-based AI agents that can:

- Listen to user speech and convert it to text
- Maintain conversation context across multiple exchanges
- Generate appropriate responses using LLMs
- Convert responses back to natural-sounding speech
- Handle all of this in real-time for natural conversations

Rather than dealing with the complexity of coordinating multiple AI services and managing real-time audio, Pipecat handles the orchestration for you. You can focus on defining your agent's behavior and let Pipecat manage the technical details of real-time processing and service integration.

```python
# Example voice assistant pipeline
# (We'll explain how this works in detail in later sections)
pipeline = Pipeline([
    transport.input(),           # Audio input
    transcription_service,       # Speech-to-text
    llm_context_aggregator,      # Manages conversation context
    llm_service,                 # Processes with LLM
    tts_service,                # Text-to-speech
    transport.output()          # Audio output
])
```

### Multimodal Applications

Pipecat excels at handling multiple data types simultaneously:

- Audio streams for voice interaction
- Video frames for visual processing
- Text for LLM interaction
- Generated images for visual responses

### Real-time AI Processing

Built to handle streaming AI workloads:

- Continuous speech recognition
- Real-time LLM interactions
- Dynamic audio/video generation
- Interactive media processing

## System Requirements

### Basic Requirements

- Python 3.10+
- Async IO support
- Network connectivity for service integration

### Optional Dependencies

```bash
# Install with basic dependencies
pip install pipecat-ai

# Install with specific service support
pip install "pipecat-ai[daily,elevenlabs,openai]"
```

### Service Accounts

While Pipecat is service-agnostic, common integrations include:

- Daily.co for WebRTC transport
- OpenAI for LLM processing
- ElevenLabs/Cartesia/Deepgram for text-to-speech
- Custom services via HTTP/WebSocket

## Getting Started

The fastest way to get started with Pipecat is to install the package and run one of our example applications:

```bash
# Create and activate virtual environment
python -m venv venv
source venv/bin/activate

# Install Pipecat with common dependencies
pip install "pipecat-ai[daily,elevenlabs]"

# Run example
python examples/foundational/01-say-one-thing.py
```

Ready to dive deeper? Continue to [Core Concepts](link) to understand how Pipecat works under the hood.

Need help? Join our [Discord community](https://discord.gg/pipecat) where you can connect with other developers, share your projects, and get support from the Pipecat team.
